{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Monthly Prediction for Asset Returns_\n",
    "\n",
    "_The following code will implement machine learning models to predict the upcoming returns of the following assets. The idea behind this code will be to run multiple models and get the best model that works for every assets. This method can help on upcoming projects, find the optimal model in the long run for each asset while using tuning of parameters. In this case, tuning is not necessary since there are not enough data points to stretch our models._ \n",
    "\n",
    "_Assets are US equities and price return is predicted on their 10-K* quarterly reports. To get even more realistic estimates we future shift this financial results by one quarter, for example, we use Q4 results published in late December to estimate price returns in Q1 of the following year. A big challenge four our project was the following dilemma, transform our returns from monthly to quarterly (upscaling) or transform quarterly earnings in monthly (downscaling). The choice was made easier by our dataset length. We had approximately 10 years of data so 120 points, if we chose the upscaling method our dataset would have had a length of 40 points, basically not enough for machine learning methods (ML). Ergo, we chose the late method, using the same earnings for three month consecutively, meaning that we would have the same results for Jan/Feb/March. We added also some lagged price returns (max 2 lags). Yes, rolling mean was choice too but using rolling mean with a window of two is not that significant._\n",
    "\n",
    "_Finally we choose a window size of 12 starting points. We train our model on the first 12 months and we predict on the following month. We choose to minimise the MAE, to have a better understanding of our error. We predict the (12 + 1) 13th month, and our step is of 1, meaning that our dataset grows in time. The first prediction uses 12 data points, second one uses 13 data points, and the last one uses the (n - 1) data points (n being the length of the dataset). To be precise the full length of our dataset is n - 2 since we lagged the price by two periods._\n",
    "\n",
    "_Finally we construct portfolio weights using the returns predicted and back-testing on the real data. This part will be available in the next notebook._\n",
    "\n",
    "\n",
    "_**A 10-K is a comprehensive report filed annually by public companies about their financial performance.**_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T18:50:41.421628Z",
     "start_time": "2020-04-06T18:50:39.152518Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T18:50:41.429452Z",
     "start_time": "2020-04-06T18:50:41.423465Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path= \"../data/\"\n",
    "# List of equities\n",
    "list_col = ['HES US Equity', 'NEM US Equity', 'INTC US Equity', 'IFF US Equity',\n",
    "       'MOS US Equity', 'EXC US Equity', 'KMB US Equity', 'JNJ US Equity',\n",
    "       'BAX US Equity', 'F US Equity', 'COP US Equity',\n",
    "       'WFC US Equity', 'WY US Equity', 'TGT US Equity', 'MMM US Equity',\n",
    "       'CMI US Equity', 'HAS US Equity', 'DUK US Equity',\n",
    "       'EMN US Equity', 'BK US Equity', 'UFS US Equity', 'ECL US Equity',\n",
    "       'SLB US Equity', 'UPS US Equity', 'T US Equity', 'NSC US Equity',\n",
    "       'PPL US Equity', 'MO US Equity', 'JLL US Equity', 'C US Equity',\n",
    "       'ABT US Equity', 'AMD US Equity', 'CVX US Equity', 'CMA US Equity',\n",
    "       'DTE US Equity', 'HSY US Equity', 'KIM US Equity', 'NBL US Equity',\n",
    "       'IBM US Equity', 'WELL US Equity', 'IR US Equity', 'BKR US Equity',\n",
    "       'WEC US Equity', 'OXY US Equity', 'WMB US Equity', 'UNP US Equity',\n",
    "       'WM US Equity', 'CCL US Equity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T18:50:41.660593Z",
     "start_time": "2020-04-06T18:50:41.431447Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading all the csv file containing price returns and financial data\n",
    "returns = pd.read_csv(file_path+\"return.csv\")[['Date1']+list_col]\n",
    "returns.rename(columns={returns.columns[0]: \"Date\" }, inplace = True)\n",
    "CURRENT_EV_TO_T12M_EBITDA = pd.read_csv(file_path+\"CURRENT_EV_TO_T12M_EBITDA.csv\")[['Date']+list_col]\n",
    "DIVIDEND_INDICATED_YIELD= pd.read_csv(file_path+\"DIVIDEND_INDICATED_YIELD.csv\")[['Date']+list_col]\n",
    "EBITDA_TO_INTEREST_EXPN = pd.read_csv(file_path+\"EBITDA_TO_INTEREST_EXPN.csv\")[['Date']+list_col]\n",
    "EBITDA_TO_REVENUE = pd.read_csv(file_path+\"EBITDA_TO_REVENUE.csv\")[['Date']+list_col]\n",
    "EPS_GROWTH = pd.read_csv(file_path+\"EPS_GROWTH.csv\")[['Date']+list_col]\n",
    "EQY_DVD_YLD_IND = pd.read_csv(file_path+\"EQY_DVD_YLD_IND.csv\")[['Date']+list_col]\n",
    "PE_RATIO = pd.read_csv(file_path+\"PE_RATIO.csv\")[['Date']+list_col]\n",
    "TOT_DEBT_TO_EBITDA = pd.read_csv(file_path+\"TOT_DEBT_TO_EBITDA.csv\")[['Date']+list_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T18:50:41.669508Z",
     "start_time": "2020-04-06T18:50:41.661528Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not taking EPS growth because if NaN values \n",
    "list_df_str = [\n",
    "            'CURRENT_EV_TO_T12M_EBITDA','DIVIDEND_INDICATED_YIELD','EBITDA_TO_INTEREST_EXPN',\n",
    "            'EBITDA_TO_REVENUE','EQY_DVD_YLD_IND','PE_RATIO','TOT_DEBT_TO_EBITDA'\n",
    "          ]\n",
    "list_df = [\n",
    "            CURRENT_EV_TO_T12M_EBITDA,DIVIDEND_INDICATED_YIELD,EBITDA_TO_INTEREST_EXPN,\n",
    "            EBITDA_TO_REVENUE,EQY_DVD_YLD_IND,PE_RATIO,TOT_DEBT_TO_EBITDA\n",
    "          ]\n",
    "len(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T18:50:41.691482Z",
     "start_time": "2020-04-06T18:50:41.671534Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform(col, timeline, lags):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function, will create a dataframe for each asset with the according financial records and the lagged price.\n",
    "    \n",
    "    col : name of the column of the asset (string)\n",
    "    timeline: you can choose between \"Monthly\" and \"Quarterly\". We use manually but the option is open.\n",
    "    lags : Accepting integers for the number of lags to add to the dataset\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df = returns[[\"Date\",str(col)]].copy()\n",
    "    df.Date = pd.to_datetime(df.Date)\n",
    "    df.Date = df.Date.dt.strftime('%m/%Y')\n",
    "    df_final = df.copy()\n",
    "    \n",
    "    for res,res_str in zip(list_df,list_df_str):\n",
    "\n",
    "        df2 = res[[\"Date\",str(col)]].copy()\n",
    "        df2.Date = pd.to_datetime(df2.Date)\n",
    "        df2.rename(columns={str(col): str(res_str) }, inplace = True)\n",
    "        # Shifting our financial records from Q4 to Q1\n",
    "        df2.Date = df2.Date + pd.DateOffset(months=1)\n",
    "        df2.Date = df2.Date.dt.strftime('%m/%Y')\n",
    "        \n",
    "        if timeline == 'Monthly':\n",
    "            # Filling the upcoming months with the previous data\n",
    "            df_final = pd.merge(df_final,df2,on='Date', how='outer').fillna(method='ffill').dropna()\n",
    "        elif timeline == 'Quarterly':\n",
    "            # Merging only on quarterly data.\n",
    "            df_final = pd.merge(df_final,df2,on='Date', how='outer').dropna()    \n",
    "\n",
    "    for l in range(1,lags+1):\n",
    "        # Number of lags\n",
    "        df_final[col+'lag'+str(l)] = df_final[col].shift(int(l),axis = 0)\n",
    "        \n",
    "    df_final.dropna(inplace = True)\n",
    "    df_final.reset_index(drop=True,inplace = True)\n",
    "    df_final.Date = pd.to_datetime(df_final.Date)\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T18:50:41.722375Z",
     "start_time": "2020-04-06T18:50:41.693444Z"
    }
   },
   "outputs": [],
   "source": [
    "def regressonModels(col, timeline, lags):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function will take the dataframe created in the previous function and will perform the ML models.\n",
    "    The inputs are the same as in the previous function since it will be called in this part. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Creation d'une liste avec les modeles qui vont être appliqués\n",
    "    from xgboost import XGBRegressor\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.ensemble import AdaBoostRegressor\n",
    "    from catboost import CatBoostRegressor\n",
    "    from lightgbm import LGBMRegressor\n",
    "    from sklearn.linear_model import SGDRegressor\n",
    "    from sklearn import metrics\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # Creating a list to rotate models.\n",
    "    models = []\n",
    "    models.append(XGBRegressor(silent=True))\n",
    "    models.append(GradientBoostingRegressor(verbose = 0))\n",
    "    models.append(RandomForestRegressor(verbose=0))\n",
    "    models.append(AdaBoostRegressor())\n",
    "    models.append(CatBoostRegressor(silent=True))\n",
    "    models.append(LGBMRegressor(silent=True))\n",
    "    models.append(SGDRegressor())    \n",
    "\n",
    "    \n",
    "    df_final = transform(col, timeline, lags)\n",
    "    y = df_final[[col]].copy()\n",
    "    date = df_final['Date'].to_list()\n",
    "    X = df_final.drop(['Date',col],axis=1).copy()\n",
    "    # Scaling data\n",
    "    sc = StandardScaler()\n",
    "    X[X.columns] = sc.fit_transform(X[X.columns])\n",
    "    \n",
    "    if timeline == \"Monthly\":\n",
    "        window_size = 12\n",
    "        step_size = 1\n",
    "        backtest_size = 1\n",
    "    elif timeline == \"Quarterly\":\n",
    "        window_size = 4\n",
    "        step_size = 1\n",
    "        backtest_size = 1        \n",
    "        \n",
    "        \n",
    "    i = 0 \n",
    "    results = []\n",
    "    date_of_pred = []\n",
    "    names = []\n",
    "    \n",
    "    ##################\n",
    "    results_y_pred = []\n",
    "    #################\n",
    "\n",
    "    for m in models:\n",
    "        m = str(m).split('(')[0]\n",
    "        names.append(m)\n",
    "\n",
    "    while i + window_size <= X.shape[0]:\n",
    "\n",
    "#         print(\"Current index\"+str(i))\n",
    "\n",
    "        # We take the first i + window size data points\n",
    "        sample_X = X.iloc[:i+window_size,:].copy()\n",
    "        sample_Y = y.iloc[:i+window_size].copy()\n",
    "        # We train it in the first i + window size - 1 points\n",
    "        X_train = sample_X.iloc[:-backtest_size,:].copy()\n",
    "        Y_train = sample_Y.iloc[:-backtest_size].copy()\n",
    "        # We test for the following month (so we try to predict only one month)\n",
    "        X_test = sample_X.iloc[-backtest_size:,:].copy()\n",
    "        Y_test = sample_Y.iloc[-backtest_size:].copy()\n",
    "        #date_of_pred.append(str(date[X_test.index[-1]]))\n",
    "        date_of_pred.append(str(date[X_train.index[0]]) + '-' + str(date[X_test.index[-1]]))\n",
    "\n",
    "        \"\"\"\n",
    "        In case we want to calculate more than the next month, this will take the first \n",
    "        and the last date of the X_test\n",
    "        date_of_pred.append(str(date[X_test.index[0]]) + '-' + str(date[X_test.index[-1]]))\n",
    "        \"\"\"\n",
    "\n",
    "        modelscore = []\n",
    "        y_predit_list = []\n",
    "        # Rotating models, predicting our t+1, also collecting the MAE for our final report.\n",
    "        for model in models:\n",
    "\n",
    "            model.fit(X_train,Y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_predit_list.append(y_pred[0])\n",
    "            # Mean absolute error\n",
    "            score = metrics.mean_absolute_error(Y_test, y_pred)\n",
    "            modelscore.append(score)\n",
    "\n",
    "        results_y_pred.append(y_predit_list)\n",
    "        results.append(modelscore)\n",
    "\n",
    "        i+=step_size\n",
    "        \n",
    "    # Returning \n",
    "    \n",
    "    results_summary = pd.DataFrame(results,columns = names)\n",
    "    #results_summary.insert(0,\"period_of_pred\",date_of_pred)\n",
    "    results_summary['Best_model'] = results_summary.idxmin(axis=1)\n",
    "    best_m = results_summary.head(1)['Best_model'].values[0]\n",
    "    \n",
    "    \n",
    "    results_y_pred = pd.DataFrame(results_y_pred,columns = names)\n",
    "    val_of_y = list(results_y_pred[best_m])\n",
    "    \n",
    "    print('Ticker '+str(col)+' finished')    \n",
    "    \n",
    "    return col , best_m , val_of_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T22:37:31.435569Z",
     "start_time": "2020-04-09T22:37:31.419737Z"
    }
   },
   "outputs": [],
   "source": [
    "asset_list = []\n",
    "best_model_list = []\n",
    "val_of_y_list = []\n",
    "\n",
    "# This for loop will loop through all the list of dataframes and perform transformation + ML prediction and store those in \n",
    "# lists that are created.\n",
    "for asset in list_col:\n",
    "    ass , best_m, val_of_y = regressonModels(str(asset), 'Monthly', 2)\n",
    "    asset_list.append(ass)\n",
    "    best_model_list.append(best_m)\n",
    "    val_of_y_list.append(val_of_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T19:17:07.050852Z",
     "start_time": "2020-04-06T19:17:07.043871Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating a daataframe with the assets name, the best model used in each asset and the predicted returns \n",
    "for the n-12 periods\n",
    "\"\"\"\n",
    "\n",
    "final_results = pd.DataFrame()\n",
    "final_results['Asset'] = asset_list\n",
    "final_results['Model'] = best_model_list\n",
    "final_results['Returns_predict'] = val_of_y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T19:17:08.144596Z",
     "start_time": "2020-04-06T19:17:08.119662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asset</th>\n",
       "      <th>Model</th>\n",
       "      <th>Returns_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HES US Equity</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-2.809064600000006, 0.6152145699999998, -4.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEM US Equity</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[-1.7914076059999997, -0.9033056110000004, -4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTC US Equity</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[3.1969774527983232, 3.313437153895696, 3.1351...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IFF US Equity</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[2.137643337249756, 4.116685390472412, 0.60484...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MOS US Equity</td>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>[-0.2642870545387268, -8.006417274475098, 7.39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EXC US Equity</td>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>[-0.9027720666666665, -0.8123149333333334, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KMB US Equity</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>[0.4350848799999998, -0.16565399600000016, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JNJ US Equity</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>[-0.12326520410451022, -0.41003084431091946, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BAX US Equity</td>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>[2.6847617651458355, 4.176697672749186, -4.863...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Asset                  Model  \\\n",
       "0   HES US Equity  RandomForestRegressor   \n",
       "1   NEM US Equity  RandomForestRegressor   \n",
       "2  INTC US Equity          LGBMRegressor   \n",
       "3   IFF US Equity           XGBRegressor   \n",
       "4   MOS US Equity           XGBRegressor   \n",
       "5   EXC US Equity      AdaBoostRegressor   \n",
       "6   KMB US Equity  RandomForestRegressor   \n",
       "7   JNJ US Equity          LGBMRegressor   \n",
       "8   BAX US Equity           SGDRegressor   \n",
       "\n",
       "                                     Returns_predict  \n",
       "0  [-2.809064600000006, 0.6152145699999998, -4.06...  \n",
       "1  [-1.7914076059999997, -0.9033056110000004, -4....  \n",
       "2  [3.1969774527983232, 3.313437153895696, 3.1351...  \n",
       "3  [2.137643337249756, 4.116685390472412, 0.60484...  \n",
       "4  [-0.2642870545387268, -8.006417274475098, 7.39...  \n",
       "5  [-0.9027720666666665, -0.8123149333333334, -0....  \n",
       "6  [0.4350848799999998, -0.16565399600000016, -0....  \n",
       "7  [-0.12326520410451022, -0.41003084431091946, 0...  \n",
       "8  [2.6847617651458355, 4.176697672749186, -4.863...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
